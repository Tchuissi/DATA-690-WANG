{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "travail rudy xml",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPr8D2nTUxVC4h+XejOxMgr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tchuissi/DATA-690-WANG/blob/master/travail_rudy_xml.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnKDpx63BXAx"
      },
      "source": [
        "#**Assignment 4**\n",
        "\n",
        "I provide you with a compressed XML file. Some of the fields contain HTML. ​\n",
        "\n",
        "- Extract the XML from the .zip file. In Python, use a module to parse the XML (do not write an XML parser)​\n",
        "\n",
        "- Using Python, extract the HTML from the XML. Then use BeautifulSoup4 to parse the HTML \n",
        "\n",
        "- For each HTML page, report the number of links (URLs with the tag < a href=\"URL\">text) in each HTML page \n",
        "\n",
        "- Submit a single Jupyter notebook that parses the XML file and produces the count of links per HTML file.​\n",
        "Advanced students: if you complete the assignment above and are are seeking a challenge, use an alternative method (i.e., regular expressions or Python's find) to validate the count of HTML links per page reported by BeautifulSoup4 .​ ​\n",
        "\n",
        "When you are done with the assignment or have spent an hour on the homework (whichever comes first), please send me an email indicating which of these you have reached​ ​\n",
        "\n",
        "To: jhwan@umbc.edu​\n",
        "\n",
        "Subject: Data 601 Fall 2020 Week 10 remove stop words​\n",
        "\n",
        "Examples of content: \"I have spent 1 hour on the homework\" or \"I am done with the assignment in 20 minutes.\"​\n",
        "\n",
        "If you've not completed the homework, please specify what your status is.​"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ip03792jqsn8"
      },
      "source": [
        "#**Question 1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENMPz7ORpMZI",
        "outputId": "d7d408c9-7fa7-4ac9-f10d-4a49fce86731",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from lxml import etree\n",
        "\n",
        "tree = etree.parse(\"xml_containing_html.xml\")\n",
        "root = tree.getroot()     #it will take the first nod\n",
        "print(root)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<Element all_pages at 0x7f4591646dc8>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74hb3WO3SE0F",
        "outputId": "6075aff1-5db0-4ed9-c3fc-49d67f059d7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "pip install beautifulsoup4"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (4.6.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofFh48YcpTtY",
        "outputId": "0ee663ae-f31c-461a-ce91-e51fb3848f6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "count=0\n",
        "for child in root:  #Parse the XML\n",
        "  #print(child)\n",
        "  for attributes in child:\n",
        "    if (attributes.tag==\"content\"):   #attributes have two elements: tag and text\n",
        "      count+= 1\n",
        "      print(count)\n",
        "      soup=BeautifulSoup(attributes.text)     #number of links\n",
        "      html_doc=soup.find_all('a')\n",
        "      print((len(html_doc)))\n",
        "     #print(attributes)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "5\n",
            "2\n",
            "5\n",
            "3\n",
            "4\n",
            "4\n",
            "5\n",
            "5\n",
            "5\n",
            "6\n",
            "4\n",
            "7\n",
            "4\n",
            "8\n",
            "3\n",
            "9\n",
            "3\n",
            "10\n",
            "4\n",
            "11\n",
            "6\n",
            "12\n",
            "3\n",
            "13\n",
            "5\n",
            "14\n",
            "5\n",
            "15\n",
            "4\n",
            "16\n",
            "4\n",
            "17\n",
            "5\n",
            "18\n",
            "5\n",
            "19\n",
            "3\n",
            "20\n",
            "3\n",
            "21\n",
            "4\n",
            "22\n",
            "3\n",
            "23\n",
            "3\n",
            "24\n",
            "4\n",
            "25\n",
            "4\n",
            "26\n",
            "3\n",
            "27\n",
            "5\n",
            "28\n",
            "4\n",
            "29\n",
            "4\n",
            "30\n",
            "3\n",
            "31\n",
            "3\n",
            "32\n",
            "5\n",
            "33\n",
            "4\n",
            "34\n",
            "3\n",
            "35\n",
            "5\n",
            "36\n",
            "5\n",
            "37\n",
            "4\n",
            "38\n",
            "5\n",
            "39\n",
            "4\n",
            "40\n",
            "4\n",
            "41\n",
            "4\n",
            "42\n",
            "3\n",
            "43\n",
            "6\n",
            "44\n",
            "6\n",
            "45\n",
            "4\n",
            "46\n",
            "3\n",
            "47\n",
            "4\n",
            "48\n",
            "4\n",
            "49\n",
            "4\n",
            "50\n",
            "3\n",
            "51\n",
            "4\n",
            "52\n",
            "4\n",
            "53\n",
            "5\n",
            "54\n",
            "3\n",
            "55\n",
            "4\n",
            "56\n",
            "4\n",
            "57\n",
            "3\n",
            "58\n",
            "5\n",
            "59\n",
            "6\n",
            "60\n",
            "3\n",
            "61\n",
            "3\n",
            "62\n",
            "4\n",
            "63\n",
            "5\n",
            "64\n",
            "4\n",
            "65\n",
            "4\n",
            "66\n",
            "3\n",
            "67\n",
            "3\n",
            "68\n",
            "5\n",
            "69\n",
            "6\n",
            "70\n",
            "4\n",
            "71\n",
            "4\n",
            "72\n",
            "5\n",
            "73\n",
            "3\n",
            "74\n",
            "5\n",
            "75\n",
            "4\n",
            "76\n",
            "3\n",
            "77\n",
            "5\n",
            "78\n",
            "4\n",
            "79\n",
            "3\n",
            "80\n",
            "3\n",
            "81\n",
            "3\n",
            "82\n",
            "4\n",
            "83\n",
            "3\n",
            "84\n",
            "4\n",
            "85\n",
            "4\n",
            "86\n",
            "3\n",
            "87\n",
            "4\n",
            "88\n",
            "4\n",
            "89\n",
            "5\n",
            "90\n",
            "5\n",
            "91\n",
            "3\n",
            "92\n",
            "3\n",
            "93\n",
            "5\n",
            "94\n",
            "5\n",
            "95\n",
            "5\n",
            "96\n",
            "3\n",
            "97\n",
            "5\n",
            "98\n",
            "5\n",
            "99\n",
            "5\n",
            "100\n",
            "4\n",
            "101\n",
            "3\n",
            "102\n",
            "4\n",
            "103\n",
            "3\n",
            "104\n",
            "3\n",
            "105\n",
            "5\n",
            "106\n",
            "4\n",
            "107\n",
            "3\n",
            "108\n",
            "3\n",
            "109\n",
            "3\n",
            "110\n",
            "4\n",
            "111\n",
            "4\n",
            "112\n",
            "3\n",
            "113\n",
            "5\n",
            "114\n",
            "4\n",
            "115\n",
            "4\n",
            "116\n",
            "4\n",
            "117\n",
            "5\n",
            "118\n",
            "4\n",
            "119\n",
            "4\n",
            "120\n",
            "5\n",
            "121\n",
            "3\n",
            "122\n",
            "3\n",
            "123\n",
            "4\n",
            "124\n",
            "3\n",
            "125\n",
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrd_ALXdq4e6"
      },
      "source": [
        "#**Question 2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvpjf1GMpX37"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoGhghG6k79e"
      },
      "source": [
        "# Nouvelle section"
      ]
    }
  ]
}